{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Seyed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Seyed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Seyed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Seyed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Seyed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Seyed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from keras.layers import Dense, Activation, BatchNormalization, Concatenate\n",
    "from keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagetoTest = 1\n",
    "run = 0\n",
    "UseIMage = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from variables import *\n",
    "from models import *\n",
    "from utils import *\n",
    "from datas import *\n",
    "import AT_Classes as Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_XYZ = ['False']\n",
    "lst_useImage = ['True']\n",
    "useEndpointFeatures = 'True'\n",
    "kernel_initializer='he_uniform'\n",
    "rotation_degrees = [0,90,180,270]\n",
    "flips = ['right']\n",
    "UseConv = True\n",
    "rotated_IMs = np.zeros([13,13,13,len(rotation_degrees)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch  = 100\n",
    "batch_size = 50 #50\n",
    "verbose=1 #verbose=1 will show you an animated progress bar\n",
    "doSMOTE = False #do replicate data using SMOTE method\n",
    "learning_Rate = 0.001 # default  =0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1\n"
     ]
    }
   ],
   "source": [
    "x = datetime.datetime.today()\n",
    "nowTimeDate = x.strftime(\"%b_%d_%H_%M\")\n",
    "# PltNAme = 'AT_XYZ_is_'+str(useXYZ_Positions)+'_'+str(ImagetoTest)+'_run=2'+nowTimeDate\n",
    "\n",
    "PltNAme = 'NEW_SmallUnet1TEST18INV_FEATURES_CONV=' + str(UseConv) + '_LR=' + str(learning_Rate) + '_100_sce_' + str(\n",
    "    kernel_initializer) + '_IM=' + str(ImagetoTest) + 'bchSiz=' + str(batch_size) + '_Use_IM=' + str(\n",
    "    UseIMage) + '_Epoch=' + str(\n",
    "    epoch) + '_run=' + str(run + 1)\n",
    "print(PltNAme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Seyed/Documents/TraceProofreading/data/datafeed/IMonce_limit100scen_NEW_Inv_FEATURES.mat\n"
     ]
    }
   ],
   "source": [
    "# filepath = 'E:\\AutomatedTraceResults\\DataForConnectingTraining\\Data_For_AE_BranchScenarios\\IMonce_limit100scen_NEW_Inv_FEATURES.mat'\n",
    "filepath = root_dir+'/data/datafeed/IMonce_limit100scen_NEW_Inv_FEATURES.mat'\n",
    "print(filepath)\n",
    "ScenariosData = sio.loadmat(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMnums = ScenariosData['IMnum']\n",
    "Features = ScenariosData['NewFeatures']\n",
    "IMs = ScenariosData['IMs']\n",
    "Scenarios = ScenariosData['Scenarios']\n",
    "Labels = ScenariosData['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxNumPoints = 12\n",
    "IMsTrain = []\n",
    "FeatureTrain = []\n",
    "LabelsTrain = []\n",
    "ScenariosTrain = []\n",
    "\n",
    "IMsTest = []\n",
    "FeatureTest = []\n",
    "LabelsTest = []\n",
    "ScenariosTest = []\n",
    "\n",
    "\n",
    "UseUpper = False\n",
    "numScenarios = Scenarios.shape\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(numScenarios[1]):\n",
    "    scenario = Scenarios[0,i]\n",
    "\n",
    "    IM = IMs[0,i]\n",
    "    # print(IM.shape)\n",
    "    Feature = Features[0, i]\n",
    "\n",
    "\n",
    "    # if scenario.shape[0] == 3:\n",
    "    #     maxNumPoints = 3\n",
    "\n",
    "    # for r in range(len(rotation_degrees)):\n",
    "    #     degree = rotation_degrees[r]\n",
    "    #     print(degree)\n",
    "    #     rotated_IMs[:,:,:,r] = scipy.ndimage.interpolation.rotate(IM, degree, mode='nearest', reshape=False)\n",
    "    #     # IM_Proj = Classes.IM3D.Z_Projection(rotated_IMs[:,:,:,r])\n",
    "    #     # Classes.IM3D.plt(IM_Proj)\n",
    "\n",
    "    Label = Labels[0, i]\n",
    "    # print(scenarios.shape)\n",
    "    # if scenario.any():\n",
    "    # scenarios.shape[2]\n",
    "\n",
    "    S = Classes.cl_scenario(maxNumPoints, scenario.shape[0],scenario,0)\n",
    "    if UseUpper:\n",
    "        scenario_arr = S.getUpperArr()\n",
    "    else:\n",
    "        scenario_arr = S.getWholeArr()\n",
    "\n",
    "    if IMnums[0, i] != ImagetoTest:\n",
    "        ScenariosTrain.append(scenario_arr)\n",
    "        IMsTrain.append(IM)\n",
    "\n",
    "        FeatureTrain.append(Feature)\n",
    "\n",
    "        LabelsTrain.append(Label)\n",
    "\n",
    "    else:\n",
    "        ScenariosTest.append(scenario_arr)\n",
    "        IMsTest.append(IM)\n",
    "        FeatureTest.append(Feature)\n",
    "\n",
    "        LabelsTest.append(Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3633, 2197)\n",
      "(3633, 108)\n",
      "(3633, 144)\n",
      "(3633,)\n"
     ]
    }
   ],
   "source": [
    "ScenariosTrain = np.asarray(ScenariosTrain, dtype=np.float)\n",
    "IMsTrain = np.asarray(IMsTrain, dtype=np.float)\n",
    "IMsTrain3D = IMsTrain\n",
    "FeatureTrain = np.asarray(FeatureTrain, dtype=np.float)\n",
    "FeatureTrain = FeatureTrain[:,0,:]\n",
    "\n",
    "\n",
    "LabelsTrain = np.asarray(LabelsTrain, dtype=np.float)\n",
    "LabelsTrain = LabelsTrain[:,0]\n",
    "LabelsTrain = LabelsTrain[:,0]\n",
    "IMsTrain1 = np.reshape(IMsTrain, [IMsTrain.shape[0],np.product(IMsTrain[0,:,:,:].shape)])\n",
    "\n",
    "ScenariosTest = np.asarray(ScenariosTest, dtype=np.float)\n",
    "IMsTest = np.asarray(IMsTest, dtype=np.float)\n",
    "IMsTest3D = IMsTest\n",
    "FeatureTest = np.asarray(FeatureTest, dtype=np.float)\n",
    "FeatureTest = FeatureTest[:,0,:]\n",
    "\n",
    "# Endpoint_features_Test = Endpoint_features_Test[:, :, 0]\n",
    "LabelsTest = np.asarray(LabelsTest, dtype=np.float)\n",
    "LabelsTest = LabelsTest[:,0]\n",
    "LabelsTest = LabelsTest[:,0]\n",
    "IMsTest1 = np.reshape(IMsTest, [IMsTest.shape[0],np.product(IMsTest[0,:,:,:].shape)])\n",
    "\n",
    "# Sbhuffle Data\n",
    "indices = np.arange(len(ScenariosTrain))\n",
    "np.random.shuffle(indices)\n",
    "ScenariosTrain = ScenariosTrain[indices]\n",
    "IMsTrain = IMsTrain[indices]\n",
    "FeatureTrain = FeatureTrain[indices]\n",
    "\n",
    "LabelsTrain = LabelsTrain[indices]\n",
    "\n",
    "XIMs_train = IMsTrain1\n",
    "\n",
    "XFeature_train = FeatureTrain\n",
    "\n",
    "XScenarios_train = ScenariosTrain\n",
    "yIMs_train = LabelsTrain\n",
    "\n",
    "XIMs_test = IMsTest1\n",
    "XFeature_test = FeatureTest\n",
    "\n",
    "XScenarios_test = ScenariosTest\n",
    "yIMs_test = LabelsTest\n",
    "yFeature_test = LabelsTest\n",
    "yScenarios_test = LabelsTest\n",
    "\n",
    "print(XIMs_train.shape)\n",
    "print(XFeature_train.shape)\n",
    "print(XScenarios_train.shape)\n",
    "print(yIMs_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ignore image data\n",
    "if UseIMage == False:\n",
    "    XIMs_train = np.zeros(XIMs_train.shape)\n",
    "    XIMs_test = np.zeros(XIMs_test.shape)\n",
    "    print('Not Using Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv3D, MaxPooling3D, Input, Dense, Flatten\n",
    "from keras.layers import (Concatenate, Conv3D, Dropout, Input,\n",
    "                          Dense, MaxPooling3D, UpSampling3D, Activation, Reshape, Lambda,\n",
    "                          Permute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Seyed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "def ConvolutionBlock(x, name, fms, params):\n",
    "    x = Conv3D(filters=fms, **params, name=name+\"_conv0\")(x)\n",
    "    x = BatchNormalization(name=name+\"_bn0\")(x)\n",
    "    x = Activation(\"relu\", name=name+\"_relu0\")(x)\n",
    "\n",
    "    x = Conv3D(filters=fms, **params, name=name+\"_conv1\")(x)\n",
    "    x = BatchNormalization(name=name+\"_bn1\")(x)\n",
    "    x = Activation(\"relu\", name=name)(x)\n",
    "    return x\n",
    "\n",
    "if UseConv:\n",
    "    fms = 8\n",
    "    input1 = Input(shape=(13, 13, 13, 1), name=\"inputs\")\n",
    "\n",
    "    params = dict(kernel_size=(3, 3, 3), activation=None,\n",
    "                  padding=\"same\", kernel_initializer=\"he_uniform\")\n",
    "\n",
    "    # Transposed convolution parameters\n",
    "    params_trans = dict(kernel_size=(2, 2, 2), strides=(2, 2, 2), padding=\"same\")\n",
    "\n",
    "    # BEGIN - Encoding path\n",
    "    encodeA = ConvolutionBlock(input1, \"encodeA\", fms, params)\n",
    "    poolA = MaxPooling3D(name=\"poolA\", pool_size=(2, 2, 2))(encodeA)\n",
    "\n",
    "    encodeB = ConvolutionBlock(poolA, \"encodeB\", fms * 2, params)\n",
    "    poolB = MaxPooling3D(name=\"poolB\", pool_size=(2, 2, 2))(encodeB)\n",
    "    #\n",
    "    # encodeC = ConvolutionBlock(poolB, \"encodeC\", fms * 4, params)\n",
    "    # poolC = MaxPooling3D(name=\"poolC\", pool_size=(2, 2, 2))(encodeC)\n",
    "    #\n",
    "    # encodeD = ConvolutionBlock(poolC, \"encodeD\", fms * 8, params)\n",
    "\n",
    "    x2 = Flatten()(poolB)\n",
    "else:\n",
    "    # # Relu\n",
    "    input1 = keras.layers.Input(shape=(XIMs_train.shape[1],))\n",
    "    # ,kernel_regularizer=keras.regularizers.l2(l=0.2)\n",
    "    x1 = keras.layers.Dense(32, input_dim=XIMs_train.shape[1], activation='relu')(input1)\n",
    "    x2 = keras.layers.Dense(16, input_dim=XIMs_train.shape[1], activation='relu')(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relu\n",
    "input3 = keras.layers.Input(shape=(XFeature_train.shape[1],))\n",
    "xxx0 = keras.layers.Dense(32, input_dim=XFeature_train.shape[1], activation='relu')(input3)\n",
    "xxx1 = keras.layers.Dense(16, input_dim=XFeature_train.shape[1], activation='relu')(xxx0)\n",
    "# xxx2 = keras.layers.Dense(8, input_dim=XFeature_train.shape[1], activation='relu')(xxx1)\n",
    "# xxx2 = keras.layers.Dense(16, activation='relu')(xxx1)\n",
    "# xxx3 = keras.layers.Dense(8, activation='relu')(xxx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = keras.layers.concatenate([x2, xxx1])\n",
    "# Relu\n",
    "out = keras.layers.Dense(4, activation='sigmoid')(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = keras.layers.Dense(1, activation='sigmoid')(out)\n",
    "model = keras.models.Model(inputs=[input1, input3], outputs=out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=learning_Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'],\n",
    "\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"E:/AutomatedTracing/AutomatedTracing/Python/logs/\"+PltNAme)\n",
    "# tensorboard --logdir=E:\\AutomatedTracing\\AutomatedTracing\\Python\\logs\n",
    "# http://localhost:6006/#scalars&run=AT_All3&runSelectionState=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%3D%3D&_smoothingWeight=0.586\n",
    "\n",
    "# checkpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath= root_dir+'/data/models/'+PltNAme+\"_weights.max_val_acc.hdf5\"\n",
    "checkpoint_max_val_acc = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "filepath = root_dir+'/data/models/'+ PltNAme + \"_weights.min_val_acc.hdf5\"\n",
    "checkpoint_min_val_acc = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,\n",
    "                                         mode='min')\n",
    "\n",
    "filepath = root_dir+'/data/models/'+ PltNAme + \"_weights.max_val_loss.hdf5\"\n",
    "checkpoint_max_val_loss = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "filepath = root_dir+'/data/models/'+ PltNAme + \"_weights.min_val_loss.hdf5\"\n",
    "checkpoint_min_val_loss = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                                          mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if UseConv:\n",
    "    X_IMs = IMsTrain3D.reshape(IMsTrain3D.shape[0], IMsTrain3D.shape[1], IMsTrain3D.shape[2], IMsTrain3D.shape[3],\n",
    "                       1)\n",
    "else:\n",
    "    X_IMs = XIMs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3633, 13, 13, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_IMs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Seyed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2434 samples, validate on 1199 samples\n",
      "Epoch 1/100\n",
      "2434/2434 [==============================] - 6s 3ms/step - loss: 0.5062 - accuracy: 0.8973 - val_loss: 0.5395 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00001: val_loss improved from -inf to 0.53951, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.max_val_loss.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seyed\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.53951, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 2/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.4505 - accuracy: 0.9408 - val_loss: 0.4735 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.53951 to 0.47346, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 3/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.4315 - accuracy: 0.9408 - val_loss: 0.4378 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.47346 to 0.43775, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 4/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.4142 - accuracy: 0.9408 - val_loss: 0.4160 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.43775 to 0.41604, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 5/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.3983 - accuracy: 0.9408 - val_loss: 0.3999 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.41604 to 0.39988, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 6/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.3838 - accuracy: 0.9408 - val_loss: 0.3862 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.39988 to 0.38621, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 7/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.3706 - accuracy: 0.9408 - val_loss: 0.3738 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.38621 to 0.37382, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 8/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.3584 - accuracy: 0.9408 - val_loss: 0.3628 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.37382 to 0.36277, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 9/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.3473 - accuracy: 0.9408 - val_loss: 0.3525 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.36277 to 0.35253, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 10/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.3370 - accuracy: 0.9408 - val_loss: 0.3434 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.35253 to 0.34335, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 11/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.3277 - accuracy: 0.9408 - val_loss: 0.3349 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34335 to 0.33489, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 12/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.3191 - accuracy: 0.9408 - val_loss: 0.3271 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33489 to 0.32707, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 13/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.3112 - accuracy: 0.9408 - val_loss: 0.3201 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.32707 to 0.32010, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 14/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.3040 - accuracy: 0.9408 - val_loss: 0.3136 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.32010 to 0.31362, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 15/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2974 - accuracy: 0.9408 - val_loss: 0.3076 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.31362 to 0.30765, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 16/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2912 - accuracy: 0.9408 - val_loss: 0.3024 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.30765 to 0.30239, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 17/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2857 - accuracy: 0.9408 - val_loss: 0.2974 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.30239 to 0.29740, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 18/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2805 - accuracy: 0.9408 - val_loss: 0.2930 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.29740 to 0.29296, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2759 - accuracy: 0.9408 - val_loss: 0.2887 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.29296 to 0.28873, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 20/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2715 - accuracy: 0.9408 - val_loss: 0.2850 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.28873 to 0.28503, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 21/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2676 - accuracy: 0.9408 - val_loss: 0.2816 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.28503 to 0.28162, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 22/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2639 - accuracy: 0.9408 - val_loss: 0.2785 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.28162 to 0.27848, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 23/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2606 - accuracy: 0.9408 - val_loss: 0.2756 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.27848 to 0.27562, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 24/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2575 - accuracy: 0.9408 - val_loss: 0.2731 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.27562 to 0.27310, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 25/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2547 - accuracy: 0.9408 - val_loss: 0.2707 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.27310 to 0.27066, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 26/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2521 - accuracy: 0.9408 - val_loss: 0.2685 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.27066 to 0.26846, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 27/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2497 - accuracy: 0.9408 - val_loss: 0.2666 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.26846 to 0.26660, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 28/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2476 - accuracy: 0.9408 - val_loss: 0.2647 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.26660 to 0.26474, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 29/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2455 - accuracy: 0.9408 - val_loss: 0.2632 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.26474 to 0.26320, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 30/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2437 - accuracy: 0.9408 - val_loss: 0.2617 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.26320 to 0.26167, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 31/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2420 - accuracy: 0.9408 - val_loss: 0.2602 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.26167 to 0.26023, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 32/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2365 - accuracy: 0.9408 - val_loss: 0.2442 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.26023 to 0.24419, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 33/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.2012 - accuracy: 0.9515 - val_loss: 0.2059 - val_accuracy: 0.9441\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.24419 to 0.20587, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 34/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1712 - accuracy: 0.9774 - val_loss: 0.1832 - val_accuracy: 0.9708\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.20587 to 0.18321, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 35/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1644 - accuracy: 0.9786 - val_loss: 0.1772 - val_accuracy: 0.9716\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.18321 to 0.17719, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 36/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1599 - accuracy: 0.9786 - val_loss: 0.1733 - val_accuracy: 0.9716\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.17719 to 0.17334, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1560 - accuracy: 0.9786 - val_loss: 0.1698 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.17334 to 0.16976, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 38/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1528 - accuracy: 0.9786 - val_loss: 0.1667 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.16976 to 0.16673, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 39/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1498 - accuracy: 0.9786 - val_loss: 0.1641 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.16673 to 0.16412, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 40/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1471 - accuracy: 0.9786 - val_loss: 0.1617 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.16412 to 0.16169, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 41/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1446 - accuracy: 0.9786 - val_loss: 0.1594 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.16169 to 0.15944, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 42/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1423 - accuracy: 0.9786 - val_loss: 0.1574 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.15944 to 0.15736, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 43/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1401 - accuracy: 0.9786 - val_loss: 0.1554 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.15736 to 0.15542, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 44/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1381 - accuracy: 0.9786 - val_loss: 0.1537 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.15542 to 0.15370, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 45/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1362 - accuracy: 0.9786 - val_loss: 0.1521 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.15370 to 0.15207, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 46/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1345 - accuracy: 0.9786 - val_loss: 0.1505 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.15207 to 0.15051, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 47/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1329 - accuracy: 0.9786 - val_loss: 0.1491 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.15051 to 0.14909, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 48/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1313 - accuracy: 0.9786 - val_loss: 0.1477 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.14909 to 0.14775, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 49/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1299 - accuracy: 0.9786 - val_loss: 0.1465 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.14775 to 0.14654, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 50/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1285 - accuracy: 0.9786 - val_loss: 0.1454 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14654 to 0.14538, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 51/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1273 - accuracy: 0.9786 - val_loss: 0.1443 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.14538 to 0.14430, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 52/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1261 - accuracy: 0.9786 - val_loss: 0.1433 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.14430 to 0.14328, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 53/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1249 - accuracy: 0.9786 - val_loss: 0.1423 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.14328 to 0.14231, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 54/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1239 - accuracy: 0.9786 - val_loss: 0.1414 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.14231 to 0.14142, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1228 - accuracy: 0.9786 - val_loss: 0.1406 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.14142 to 0.14057, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 56/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1219 - accuracy: 0.9786 - val_loss: 0.1398 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.14057 to 0.13983, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 57/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1210 - accuracy: 0.9786 - val_loss: 0.1391 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.13983 to 0.13906, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 58/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1201 - accuracy: 0.9786 - val_loss: 0.1384 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.13906 to 0.13836, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 59/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1193 - accuracy: 0.9786 - val_loss: 0.1377 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.13836 to 0.13771, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 60/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1186 - accuracy: 0.9786 - val_loss: 0.1371 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.13771 to 0.13710, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 61/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1178 - accuracy: 0.9786 - val_loss: 0.1365 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.13710 to 0.13652, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 62/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1172 - accuracy: 0.9786 - val_loss: 0.1360 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.13652 to 0.13599, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 63/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1165 - accuracy: 0.9786 - val_loss: 0.1355 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.13599 to 0.13548, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 64/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1159 - accuracy: 0.9786 - val_loss: 0.1350 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.13548 to 0.13500, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 65/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1153 - accuracy: 0.9786 - val_loss: 0.1345 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.13500 to 0.13454, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 66/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1147 - accuracy: 0.9786 - val_loss: 0.1341 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.13454 to 0.13412, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 67/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1142 - accuracy: 0.9786 - val_loss: 0.1337 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.13412 to 0.13370, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 68/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1137 - accuracy: 0.9786 - val_loss: 0.1334 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.13370 to 0.13336, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 69/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1133 - accuracy: 0.9786 - val_loss: 0.1330 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.13336 to 0.13298, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 70/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1128 - accuracy: 0.9786 - val_loss: 0.1327 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.13298 to 0.13266, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 71/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1124 - accuracy: 0.9786 - val_loss: 0.1323 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.13266 to 0.13233, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 72/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1120 - accuracy: 0.9786 - val_loss: 0.1320 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.13233 to 0.13202, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1116 - accuracy: 0.9786 - val_loss: 0.1318 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.13202 to 0.13176, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 74/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1112 - accuracy: 0.9786 - val_loss: 0.1315 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.13176 to 0.13151, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 75/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1109 - accuracy: 0.9786 - val_loss: 0.1313 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.13151 to 0.13127, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 76/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1106 - accuracy: 0.9786 - val_loss: 0.1310 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.13127 to 0.13103, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 77/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1102 - accuracy: 0.9786 - val_loss: 0.1308 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.13103 to 0.13081, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 78/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1099 - accuracy: 0.9786 - val_loss: 0.1306 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.13081 to 0.13061, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 79/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1097 - accuracy: 0.9786 - val_loss: 0.1304 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.13061 to 0.13042, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 80/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1094 - accuracy: 0.9786 - val_loss: 0.1302 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.13042 to 0.13023, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 81/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1091 - accuracy: 0.9786 - val_loss: 0.1301 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.13023 to 0.13007, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 82/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1089 - accuracy: 0.9786 - val_loss: 0.1299 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.13007 to 0.12990, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 83/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1087 - accuracy: 0.9786 - val_loss: 0.1297 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.12990 to 0.12974, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 84/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1084 - accuracy: 0.9786 - val_loss: 0.1296 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.12974 to 0.12960, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 85/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1082 - accuracy: 0.9786 - val_loss: 0.1295 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.12960 to 0.12947, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 86/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1080 - accuracy: 0.9786 - val_loss: 0.1293 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.12947 to 0.12935, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 87/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1078 - accuracy: 0.9786 - val_loss: 0.1292 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.12935 to 0.12922, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 88/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1076 - accuracy: 0.9786 - val_loss: 0.1291 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.12922 to 0.12911, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 89/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1075 - accuracy: 0.9786 - val_loss: 0.1290 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.12911 to 0.12901, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 90/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1073 - accuracy: 0.9786 - val_loss: 0.1289 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.12901 to 0.12890, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1071 - accuracy: 0.9786 - val_loss: 0.1288 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.12890 to 0.12881, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 92/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1070 - accuracy: 0.9786 - val_loss: 0.1287 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.12881 to 0.12872, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 93/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1068 - accuracy: 0.9786 - val_loss: 0.1286 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.12872 to 0.12863, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 94/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1067 - accuracy: 0.9786 - val_loss: 0.1286 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.12863 to 0.12856, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 95/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1066 - accuracy: 0.9786 - val_loss: 0.1285 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.12856 to 0.12848, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 96/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1064 - accuracy: 0.9786 - val_loss: 0.1284 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.12848 to 0.12841, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 97/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1063 - accuracy: 0.9786 - val_loss: 0.1283 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.12841 to 0.12834, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 98/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1062 - accuracy: 0.9786 - val_loss: 0.1283 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.12834 to 0.12827, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 99/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1061 - accuracy: 0.9786 - val_loss: 0.1282 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.12827 to 0.12821, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n",
      "Epoch 100/100\n",
      "2434/2434 [==============================] - 3s 1ms/step - loss: 0.1060 - accuracy: 0.9786 - val_loss: 0.1282 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.53951\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.12821 to 0.12815, saving model to C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1_weights.min_val_loss.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_IMs,XFeature_train],\n",
    "                                yIMs_train,\n",
    "                                epochs=epoch,\n",
    "                                batch_size=batch_size,\n",
    "                                validation_split=0.33,\n",
    "                                verbose=1,\n",
    "                                callbacks=[checkpoint_max_val_acc,checkpoint_min_val_acc,checkpoint_max_val_loss,checkpoint_min_val_loss,tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 13, 13, 13, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encodeA_conv0 (Conv3D)          (None, 13, 13, 13, 8 224         inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encodeA_bn0 (BatchNormalization (None, 13, 13, 13, 8 32          encodeA_conv0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encodeA_relu0 (Activation)      (None, 13, 13, 13, 8 0           encodeA_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encodeA_conv1 (Conv3D)          (None, 13, 13, 13, 8 1736        encodeA_relu0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encodeA_bn1 (BatchNormalization (None, 13, 13, 13, 8 32          encodeA_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encodeA (Activation)            (None, 13, 13, 13, 8 0           encodeA_bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "poolA (MaxPooling3D)            (None, 6, 6, 6, 8)   0           encodeA[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encodeB_conv0 (Conv3D)          (None, 6, 6, 6, 16)  3472        poolA[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encodeB_bn0 (BatchNormalization (None, 6, 6, 6, 16)  64          encodeB_conv0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encodeB_relu0 (Activation)      (None, 6, 6, 6, 16)  0           encodeB_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encodeB_conv1 (Conv3D)          (None, 6, 6, 6, 16)  6928        encodeB_relu0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encodeB_bn1 (BatchNormalization (None, 6, 6, 6, 16)  64          encodeB_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encodeB (Activation)            (None, 6, 6, 6, 16)  0           encodeB_bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 108)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "poolB (MaxPooling3D)            (None, 3, 3, 3, 16)  0           encodeB[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           3488        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 432)          0           poolB[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           528         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 448)          0           flatten_1[0][0]                  \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            1796        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            5           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 18,369\n",
      "Trainable params: 18,273\n",
      "Non-trainable params: 96\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "C:/Users/Seyed/Documents/TraceProofreading/data/models/NEW_SmallUnet1TEST18INV_FEATURES_CONV=True_LR=0.0005_100_sce_he_uniform_IM=1bchSiz=50_Use_IM=True_Epoch=100_run=1.png\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "`pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m                 \u001b[0mworking_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1916\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1179\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1921\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1922\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-57d7c59671a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlogpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/data/models/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mPltNAme\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \"\"\"\n\u001b[0;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[1;32m--> 240\u001b[1;33m                        expand_nested, dpi)\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dashed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         raise OSError(\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[1;34m'`pydot` failed to call GraphViz.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[1;34m'Please install GraphViz (https://www.graphviz.org/) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             'and ensure that its executables are in the $PATH.')\n",
      "\u001b[1;31mOSError\u001b[0m: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH."
     ]
    }
   ],
   "source": [
    "model.save(root_dir+'/data/models/'+PltNAme+'.h5')\n",
    "print(model.summary())\n",
    "from keras.utils.vis_utils import plot_model\n",
    "logpath = root_dir+'/data/models/'+PltNAme+'.png'\n",
    "print(logpath)\n",
    "plot_model(model, to_file=logpath, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
